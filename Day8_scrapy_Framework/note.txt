scrapy框架

-什么是框架？
    - 就是一个继承了很多功能并且具有很强通用性的一个项目模板
-如何学习框架？
    - 专门学习框架封装额各种功能的详细用法。

-什么是scrapy？
    - 爬虫中封装好的一个明星框架。
    - 功能：
        - 高性能的持久化存储
        - 异步的数据下载
        - 高性能的数据解析
        - 分布式

-scrapy框架的基本使用
    - 环境安装：
        - mac or linux： pip install scrapy
        - Windows：
            - pip install wheel
            - 下载twisted， 下载地址为
                - https://www.lfd.uci.edu/~gohlke/pythonlibs/#Twisted
            - 安装twisted： pip install Twisted-17.1.0-cp36-cp36m-win_amd64.whl
                           pip install pywin32
                           pip install scrapy
            -测试： 在终端里输入scrapy指令，没有报错安装成功。
    - 创建一个工程： scrapy startproject xxxPro
    - cd xxxPro
    - 在spiders目录中创建爬虫文件
        - scrapy genspider spiderName www.xxx.com
    - 执行工程：
        - scrapy crawl spiderName
-scrapy数据分析

-scrapy持久化存储
    - 基于终端指令：
        - 要求：只可以将parse（）方法的返回值存储到本地的文本文件中
        - 注意： 持久化存储对应的文本文件的类型只可以为'json', 'jsonlines', 'jl', 'csv', 'xml', 'marshal', 'pickle')
        - 指令： scrapy crawl spiderName -o filePath
        - 好处： 简洁高效
        - 缺点： 局限性比较强（数据只可以存储到指定后缀的文本文件中）
    - 基于管道：
        - 编码流程：
            - 数据解析
            - 在item类中定义相关的属性
            - 将解析的数据封装存储到item类型的对象中
                -author = scrapy.Field()
                -content = scrapy.Field()
            - 将item类型的对象提交到pipelines进行持久化存储的操作
            - 在pipelines中的process_item要将接收到的item对象中存储的数据进行持久化存储
            - 在配置文件中开启pipeline，默认不开启pipeline，需手动开启
        -好处:
            - 通用性强
        -缺点:
            - 编码稍显繁琐
    - 面试题: 将爬取到的数据,一份存本地,一份存数据库
