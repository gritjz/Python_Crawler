爬⾍基础简介
什么是爬⾍：
    -通过编写程序，模拟浏览器上⽹，然后让其去互联⽹上抓取数据的过程。
爬⾍的价值：
    -实际应⽤
    -就业
爬⾍究竟是合法还是违法？
    -在法律中不被禁⽌
    -具有违法⻛险
    -善意爬⾍和恶意爬⾍
爬⾍的⻛险：
    -1.爬⾍⼲扰被访问⽹站的正常运营
    -2. 爬⾍抓取了受到法律保护的特定类型的数据或信息
避免违法：
    -优化⾃⼰的程序，避免⼲扰⽹站运⾏
    -抓取到受保护信息和商业机密等数据，要及时停⽌爬⾍
爬⾍在使⽤场景中的分类：
    -通⽤爬⾍：
	 	 抓取系统重要组成部分。 抓取的是⼀整章⻚⾯的数据。
    -聚焦爬⾍：
	 	 建⽴在通⽤爬⾍的基础之上。抓取的是⻚⾯种特定的局部内容。
    -增量式爬⾍：
	 	 监测⽹站中数据更新的情况。 只会抓取⽹站中最新更新的数据。
爬⾍中的⽭与盾：
    -反爬机制：
	 	 ⻔户⽹站，可以通过制定相应的策略或者技术⼿段，防⽌爬⾍程序进⾏⽹站数据爬取。
    -反反爬策略：
	 	 爬⾍程序可以通过制定相关的策略或者技术⼿段破解⻔户⽹站中具备的反爬机制，从⽽
    可以获取⻔户⽹站的数据。

robots.txt 协议：
    -君⼦协议。规定的⽹站中哪些数据可以被爬取，哪些数据不可以被爬取。
Http协议：
    -服务器和客户端进⾏数据交互的⼀种形式。
常⽤请求头信息（request headers）：
    -user-agent：请求载体的身份标识。
    - Connection： 请求完毕后，是断开还是保持连接
常⽤响应头信息：
    -Content-Type：服务器响应回客户端的数据类型。
https协议：
    -安全的http协议， 有数据加密。
加密⽅式：
    -对称密钥加密：同时发送密钥和数据。 传输过程中容易被获取。
    -⾮对称密钥加密：S端发公钥给U端，U端⽤公钥发送数据回到S端，S端⽤私钥解密信息。效
    率低，公钥可能会在途中被篡改。
    -证书密钥加密：添加第三⽅证书认证机构，在S端传输公钥的过程中，在公钥上添加签名，U
    端验证签名以保证公钥未被篡改。